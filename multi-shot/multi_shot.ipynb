{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Here we will import the libraries that are needed, and load the data into a pandas dataframe.\n",
    "Also, the OpenAI client will be set up and authentication is handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./dataset.csv')\n",
    "\n",
    "# Limit the number of rows (Set to None to process all rows)\n",
    "row_limit = 100  # Adjust this number based on cost considerations\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key='<API_KEY>'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_shot = \"\"\"\n",
    "Analyze the provided email text to determine if it is a phishing attempt, using the detailed contextual framework of psychological traits and cognitive biases. For each email, decide whether it is a phishing email or not and explain your reasoning. Apply the following psychological traits and cognitive biases in your analysis, with their explanations and examples:\\n\\n1. A Sense of Urgency: Pressuring the recipient to make quick decisions, often leading to insufficient consideration of consequences. Example: An email claiming account suspension within 24 hours unless a link is clicked.\\n\\n2. Inducing Fear by Threatening: Invoking fear to coerce compliance, threatening negative outcomes. Example: Email from 'tax authority' threatening legal action for unpaid taxes.\\n\\n3. Enticement with Desire: Playing on desires with too-good-to-be-true offers. Example: Email congratulating on a lottery win, requesting personal info.\\n\\n4. Authority Bias: Trust in suggestions from authority figures. Example: Email from the CEO directing urgent fund transfer.\\n\\n5. Recency Effect: Prioritizing the most recently presented information. Example: Urging donations to a fraudulent charity after a disaster.\\n\\n6. Halo Effect: Influence of overall brand impression on character feelings. Example: Email mimicking a respected brand to steal credentials.\\n\\n7. Hyperbolic Discounting: Preferring immediate rewards over larger, delayed benefits. Example: Offering an immediate discount for quick action.\\n\\n8. Curiosity Effect: Leveraging curiosity to entice seeking more information. Example: Email with a vague subject line and a malicious attachment.\\n\\nAdditionally, consider other phishing indicators like poor grammar and unusual requests for personal information. Analyze the overall context, language subtlety, and presentation of the email. Instructions: provide the analysis result in json format with the following parts:\n",
    "is_deceptive: Boolean (True for phishing, False for not phishing)\n",
    "explanation: Text explaining the reasoning behind the decision.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "In this part, every email in the provided dataset is analyzed to determine if it is a phishing email or not. \n",
    "The results are then saved to another csv file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to store the processed rows\n",
    "processed_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# Process each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if row_limit is not None and index >= row_limit:\n",
    "        break\n",
    "\n",
    "    email_text = row['text']    \n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": multi_shot},\n",
    "            {\"role\": \"user\", \"content\": email_text}\n",
    "        ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    response_json = json.loads(response)\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'text': [email_text],\n",
    "        'is_deceptive': [response_json['is_deceptive']],\n",
    "        'explanation': [response_json['explanation']],\n",
    "    })\n",
    "    processed_df = pd.concat([processed_df, new_row], ignore_index=True)\n",
    "\n",
    "# Export DataFrame to a new CSV file\n",
    "processed_df.to_csv('processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical performance analysis\n",
    "In this part, the performance of the model is analyzed using statistical measures such as accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.00%\n",
      "Precision: 91.11%\n",
      "Recall: 87.23%\n",
      "F1 Score: 89.13%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the datasets\n",
    "processed_df = pd.read_csv('./processed.csv')\n",
    "true_labels_df = pd.read_csv('./sample_labeled.csv')\n",
    "\n",
    "# Make sure the datasets are aligned if necessary. This example assumes they're already aligned.\n",
    "\n",
    "# Extracting the predicted and true labels\n",
    "y_pred = processed_df['is_deceptive'].values\n",
    "y_true = true_labels_df['is_deceptive'].values\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print the scores\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall: {recall*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Accuracy (90.00%)\n",
    "\n",
    "    Implication: An accuracy of 90% indicates that the system is quite adept at identifying both phishing and legitimate emails correctly. This level of accuracy is commendable and suggests that the system is reliable. However, it's essential to consider the dataset's balance, as accuracy might not fully capture performance nuances in imbalanced datasets.\n",
    "\n",
    "2. Precision (91.11%)\n",
    "\n",
    "    Implication: Precision is slightly higher than accuracy in this case, indicating that when the system labels an email as phishing, there is a 91.11% chance it's correct. High precision is particularly valuable in reducing the number of false positives, ensuring that legitimate emails are less likely to be mistakenly flagged as phishing, which can help maintain user trust in the system.\n",
    "\n",
    "3. Recall (87.23%)\n",
    "\n",
    "    Implication: The recall is somewhat lower than precision, indicating that while the system is good at identifying phishing emails, it misses a higher proportion of actual phishing emails compared to what it incorrectly flags. A recall of 87.23% suggests that some phishing attempts may still slip through the system, posing a potential security risk. Improving recall is critical to ensuring that fewer malicious emails reach the end-users.\n",
    "\n",
    "4. F1 Score (89.13%)\n",
    "\n",
    "    Implication: The F1 score provides a balanced view of precision and recall, and in this case, it indicates that the system has a good balance between the two but with room for improvement. An F1 score of 89.13% suggests that the system effectively identifies phishing attempts with a reasonable rate of false positives and negatives, but there might be opportunities to refine the system further to enhance its detection capabilities.\n",
    "\n",
    "### In the Context of Phishing Countermeasures:\n",
    "\n",
    "Emphasis on Minimizing False Positives: The high precision rate is beneficial for maintaining user trust and operational efficiency by ensuring that legitimate communications are not unduly interrupted.\n",
    "\n",
    "Need to Improve Detection: The slightly lower recall rate compared to precision highlights a need for improving the system's ability to catch all phishing attempts. Enhancing recall could involve refining detection algorithms or incorporating new data sources that better capture emerging phishing techniques.\n",
    "\n",
    "Balanced System with Improvement Opportunities: The F1 score shows that the system maintains a balance between precision and recall. However, the slightly lower recall suggests a potential area for improvement to make the system even more effective at thwarting phishing attempts.\n",
    "\n",
    "Continuous Improvement and Adaptation: Phishing tactics constantly evolve, so it's crucial for detection systems to adapt continually. This might include implementing machine learning models that can learn from new phishing patterns and incorporating user feedback and reporting mechanisms to identify missed phishing attempts.\n",
    "\n",
    "User Education Remains Key: Despite technological advancements in detection, educating users on recognizing and reporting phishing remains a vital component of a comprehensive security strategy. A more informed user base can act as an additional layer of defense against phishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4 Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to store the processed rows\n",
    "processed_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# Process each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if row_limit is not None and index >= row_limit:\n",
    "        break\n",
    "\n",
    "    email_text = row['text']    \n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": multi_shot},\n",
    "            {\"role\": \"user\", \"content\": email_text}\n",
    "        ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    response_json = json.loads(response)\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'text': [email_text],\n",
    "        'is_deceptive': [response_json['is_deceptive']],\n",
    "        'explanation': [response_json['explanation']],\n",
    "    })\n",
    "    processed_df = pd.concat([processed_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "# Export DataFrame to a new CSV file\n",
    "processed_df.to_csv('gpt4t-ms-processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.00%\n",
      "Precision: 89.36%\n",
      "Recall: 89.36%\n",
      "F1 Score: 89.36%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the datasets\n",
    "processed_df = pd.read_csv('./gpt4t-ms-processed.csv')\n",
    "true_labels_df = pd.read_csv('./sample_labeled.csv')\n",
    "\n",
    "# Extracting the predicted and true labels\n",
    "y_pred = processed_df['is_deceptive'].values\n",
    "y_true = true_labels_df['is_deceptive'].values\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print the scores\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall: {recall*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
